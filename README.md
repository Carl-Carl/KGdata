# KGdata
This dataset provides code to deal with raw knowledge data from Freebase and Wikidata.
Make sure your file pathes are identical to the pathes of this repository.

## About code
### Code for Wikidata
Each .py file provides output for the next one, so make sure you understand their functions as well as their correct running order.
1. `preprocess.py`: Extract all entities and triplets from train and test set. Then, store them respectively.
2. `downloader.py`: Download raw `.json` file form Wikidata according to the entities generated by `preprocess.py`. These raw data is stored in directory 'data/<dataset_name>/temp/'.
3. `generate_wiki.py`: With all the raw data, extract triplets from `.json` files(watch out `in:T` and `in:F` triplets) and generate the raw Knowledgegraph.
4. `clean.py`: In this part, triplets in test set are removed from the raw Knowledgegraph and those in train are inserted. Now, we get the KG we want.
5. `visualize.py`: Get some statistics of the KG.
